{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300e1f81-be4f-4875-8e25-d77365a6bdbf",
   "metadata": {},
   "source": [
    "# Week 6 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65149f72-17fa-46ba-9d3a-b54feb5a07da",
   "metadata": {},
   "source": [
    "#### We are required to train multiple machine learning models and evaluate their performance using metrics such as accuracy, precision, recall, and F1-score. Implement hyperparameter tuning techniques like GridSearchCV and RandomizedSearchCV to optimize model parameters. Analyze the results to select the best-performing model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e6aa3-09dd-4295-aea1-3b92829679a0",
   "metadata": {},
   "source": [
    "#### Breast Cancer Dataset is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10666ef9-3d09-4c23-9134-85d2f0fc1ab7",
   "metadata": {},
   "source": [
    "### Importing necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98dafc0a-6283-4438-bd9c-3424bb431300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f928892-99da-4458-ba0c-f57e908121c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8f3d3561-30e7-4ef9-98ea-b3367ac5bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4b67f71a-7454-4114-a2c6-e2e7ed7ce252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8ca011be-6f80-4537-b045-c5bac29259dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d7d0c14e-fb22-4fee-9188-59dd420654ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ee145-605d-4ab4-ab8b-7418f642a3f1",
   "metadata": {},
   "source": [
    "### Splitting the data into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7cc068bf-40fd-486d-acd5-e01466f7e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daddd32-3d09-4301-9cd9-c28303556834",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1aa09a3f-12a0-4037-83ba-1569d71aba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d48bb73-7a8a-4f62-adfd-c86f8eca4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-10 18:48:42,130] A new study created in memory with name: no-name-f787fc10-5bb3-47e4-9820-cdb9bfa1faf4\n",
      "[I 2025-07-10 18:48:42,348] Trial 0 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.019640263589002994, 'max_depth': 6, 'n_estimators': 337, 'min_child_weight': 2}. Best is trial 0 with value: 0.04385964912280704.\n",
      "[I 2025-07-10 18:48:42,558] Trial 1 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.07504200780321049, 'max_depth': 6, 'n_estimators': 549, 'min_child_weight': 1}. Best is trial 1 with value: 0.03508771929824561.\n",
      "[I 2025-07-10 18:48:42,714] Trial 2 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.08310258933333559, 'max_depth': 4, 'n_estimators': 458, 'min_child_weight': 4}. Best is trial 2 with value: 0.02631578947368418.\n",
      "[I 2025-07-10 18:48:42,855] Trial 3 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.03117381157076199, 'max_depth': 6, 'n_estimators': 301, 'min_child_weight': 4}. Best is trial 2 with value: 0.02631578947368418.\n",
      "[I 2025-07-10 18:48:43,082] Trial 4 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.08546140485392408, 'max_depth': 4, 'n_estimators': 688, 'min_child_weight': 4}. Best is trial 2 with value: 0.02631578947368418.\n",
      "[I 2025-07-10 18:48:43,259] Trial 5 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.07591297786875599, 'max_depth': 7, 'n_estimators': 354, 'min_child_weight': 1}. Best is trial 2 with value: 0.02631578947368418.\n",
      "[I 2025-07-10 18:48:43,445] Trial 6 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.05368479795193839, 'max_depth': 4, 'n_estimators': 584, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:43,680] Trial 7 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.08745814704900384, 'max_depth': 7, 'n_estimators': 866, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:43,779] Trial 8 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.043347079360908446, 'max_depth': 3, 'n_estimators': 186, 'min_child_weight': 1}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:43,948] Trial 9 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.04685422275504371, 'max_depth': 7, 'n_estimators': 311, 'min_child_weight': 1}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:44,220] Trial 10 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.06117314549372016, 'max_depth': 3, 'n_estimators': 978, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:44,409] Trial 11 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0993364957945986, 'max_depth': 5, 'n_estimators': 820, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:44,742] Trial 12 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.0071145118943578, 'max_depth': 4, 'n_estimators': 753, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:44,988] Trial 13 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.05465569803985631, 'max_depth': 5, 'n_estimators': 972, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:45,225] Trial 14 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.06353496677945819, 'max_depth': 4, 'n_estimators': 644, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:45,506] Trial 15 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09882719234944899, 'max_depth': 7, 'n_estimators': 864, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:45,729] Trial 16 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.033657421282415625, 'max_depth': 5, 'n_estimators': 561, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:45,970] Trial 17 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.06876590165285831, 'max_depth': 6, 'n_estimators': 887, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:46,042] Trial 18 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.08823261990152337, 'max_depth': 3, 'n_estimators': 104, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:46,289] Trial 19 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.03506297550998157, 'max_depth': 5, 'n_estimators': 598, 'min_child_weight': 2}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:46,551] Trial 20 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.018364612706580172, 'max_depth': 4, 'n_estimators': 758, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:46,751] Trial 21 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0999771336684183, 'max_depth': 5, 'n_estimators': 836, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:46,955] Trial 22 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09160263622310016, 'max_depth': 5, 'n_estimators': 768, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:47,148] Trial 23 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0775792405185308, 'max_depth': 5, 'n_estimators': 451, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:47,411] Trial 24 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09981138844072295, 'max_depth': 6, 'n_estimators': 916, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:47,621] Trial 25 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09132849485903305, 'max_depth': 4, 'n_estimators': 801, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:47,828] Trial 26 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.054944361309861085, 'max_depth': 7, 'n_estimators': 699, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:47,993] Trial 27 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.08072921127367234, 'max_depth': 5, 'n_estimators': 451, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:48,234] Trial 28 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.07025594951019751, 'max_depth': 6, 'n_estimators': 948, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:48,572] Trial 29 finished with value: 0.052631578947368474 and parameters: {'learning_rate': 0.0015345530260819154, 'max_depth': 3, 'n_estimators': 688, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:48,923] Trial 30 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.024135408137083612, 'max_depth': 4, 'n_estimators': 828, 'min_child_weight': 2}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:49,215] Trial 31 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.05693574575140693, 'max_depth': 5, 'n_estimators': 989, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:49,502] Trial 32 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.04133021172989758, 'max_depth': 5, 'n_estimators': 935, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:49,751] Trial 33 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.053809455166012425, 'max_depth': 6, 'n_estimators': 870, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:49,912] Trial 34 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.06892572986737996, 'max_depth': 5, 'n_estimators': 529, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:50,181] Trial 35 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09187574201202642, 'max_depth': 4, 'n_estimators': 931, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:50,336] Trial 36 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.04847079726818689, 'max_depth': 6, 'n_estimators': 385, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:50,597] Trial 37 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.08333813025571325, 'max_depth': 4, 'n_estimators': 998, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:50,878] Trial 38 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.06356430123258837, 'max_depth': 7, 'n_estimators': 637, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:51,016] Trial 39 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.040849875569985, 'max_depth': 6, 'n_estimators': 258, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:51,201] Trial 40 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.07201651671593035, 'max_depth': 5, 'n_estimators': 522, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:51,446] Trial 41 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.09582737703377749, 'max_depth': 7, 'n_estimators': 862, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:51,669] Trial 42 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09540753477853918, 'max_depth': 7, 'n_estimators': 793, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:51,910] Trial 43 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.08836760564814272, 'max_depth': 7, 'n_estimators': 886, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:52,159] Trial 44 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.08540371938273385, 'max_depth': 6, 'n_estimators': 724, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:52,436] Trial 45 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.08070822396826531, 'max_depth': 7, 'n_estimators': 828, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:52,730] Trial 46 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09482307267428283, 'max_depth': 3, 'n_estimators': 957, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:52,992] Trial 47 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.06104265062164707, 'max_depth': 6, 'n_estimators': 915, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:53,208] Trial 48 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.07605052591914199, 'max_depth': 7, 'n_estimators': 651, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:53,559] Trial 49 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.01854536072781559, 'max_depth': 4, 'n_estimators': 737, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:53,856] Trial 50 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.025393065683344682, 'max_depth': 5, 'n_estimators': 792, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:54,075] Trial 51 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.03359170858702055, 'max_depth': 5, 'n_estimators': 585, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:54,293] Trial 52 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.03718672441654078, 'max_depth': 5, 'n_estimators': 494, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:54,541] Trial 53 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.04383910640310375, 'max_depth': 5, 'n_estimators': 583, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:54,982] Trial 54 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.01109497025478036, 'max_depth': 4, 'n_estimators': 901, 'min_child_weight': 2}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:55,208] Trial 55 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09942756500201308, 'max_depth': 5, 'n_estimators': 842, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:55,352] Trial 56 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.050146111388576754, 'max_depth': 7, 'n_estimators': 411, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:55,567] Trial 57 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.03118469873635384, 'max_depth': 6, 'n_estimators': 620, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:55,827] Trial 58 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.08799192664621716, 'max_depth': 4, 'n_estimators': 968, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:56,034] Trial 59 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.06330522543205944, 'max_depth': 3, 'n_estimators': 480, 'min_child_weight': 1}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:56,282] Trial 60 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.05850670647995326, 'max_depth': 5, 'n_estimators': 560, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:56,556] Trial 61 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.050903044182177455, 'max_depth': 7, 'n_estimators': 878, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:56,808] Trial 62 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.04462871789706091, 'max_depth': 6, 'n_estimators': 848, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:57,004] Trial 63 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0679322504290485, 'max_depth': 6, 'n_estimators': 676, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:57,239] Trial 64 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.05307345998241398, 'max_depth': 6, 'n_estimators': 908, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:57,448] Trial 65 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.07948802666177893, 'max_depth': 7, 'n_estimators': 811, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:57,667] Trial 66 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.07309797308114584, 'max_depth': 5, 'n_estimators': 757, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:57,771] Trial 67 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.06630469970068531, 'max_depth': 5, 'n_estimators': 100, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:58,064] Trial 68 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.09260904840253859, 'max_depth': 4, 'n_estimators': 942, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:58,296] Trial 69 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09806796719112462, 'max_depth': 6, 'n_estimators': 975, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:58,510] Trial 70 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.08658110290785735, 'max_depth': 7, 'n_estimators': 778, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:58,702] Trial 71 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0963224501510247, 'max_depth': 5, 'n_estimators': 821, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:58,897] Trial 72 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0999147797965241, 'max_depth': 5, 'n_estimators': 886, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:59,097] Trial 73 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09336100857351197, 'max_depth': 5, 'n_estimators': 854, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:59,284] Trial 74 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09027714904642697, 'max_depth': 5, 'n_estimators': 712, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:59,388] Trial 75 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.05803080759762348, 'max_depth': 5, 'n_estimators': 156, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:59,529] Trial 76 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09693047901336656, 'max_depth': 6, 'n_estimators': 333, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:48:59,833] Trial 77 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0826182421465792, 'max_depth': 4, 'n_estimators': 932, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:00,073] Trial 78 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09036587509408993, 'max_depth': 5, 'n_estimators': 869, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:00,363] Trial 79 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.04668720066173364, 'max_depth': 6, 'n_estimators': 996, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:00,650] Trial 80 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.03985490382140411, 'max_depth': 7, 'n_estimators': 897, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:00,864] Trial 81 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09362323252723206, 'max_depth': 5, 'n_estimators': 776, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:01,084] Trial 82 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.08543656636394799, 'max_depth': 5, 'n_estimators': 833, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:01,304] Trial 83 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09073389969587974, 'max_depth': 5, 'n_estimators': 739, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:01,605] Trial 84 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09726856079934094, 'max_depth': 5, 'n_estimators': 804, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:01,848] Trial 85 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.0998803012703416, 'max_depth': 5, 'n_estimators': 917, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:02,076] Trial 86 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.022739224031054515, 'max_depth': 4, 'n_estimators': 539, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:02,286] Trial 87 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.07667986189107062, 'max_depth': 7, 'n_estimators': 620, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:02,487] Trial 88 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.056104874238907185, 'max_depth': 5, 'n_estimators': 669, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:02,699] Trial 89 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.02761305448906365, 'max_depth': 5, 'n_estimators': 510, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:02,916] Trial 90 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.09461954312615829, 'max_depth': 6, 'n_estimators': 769, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:03,106] Trial 91 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.0826867245965326, 'max_depth': 5, 'n_estimators': 439, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:03,352] Trial 92 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.08910933799189116, 'max_depth': 5, 'n_estimators': 401, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:03,489] Trial 93 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.07437704866888557, 'max_depth': 5, 'n_estimators': 258, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:03,752] Trial 94 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.07878384599347198, 'max_depth': 5, 'n_estimators': 954, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:03,934] Trial 95 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.08718662637769763, 'max_depth': 7, 'n_estimators': 563, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:04,167] Trial 96 finished with value: 0.04385964912280704 and parameters: {'learning_rate': 0.011892416575124472, 'max_depth': 3, 'n_estimators': 482, 'min_child_weight': 3}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:04,331] Trial 97 finished with value: 0.02631578947368418 and parameters: {'learning_rate': 0.05225476024047884, 'max_depth': 5, 'n_estimators': 373, 'min_child_weight': 4}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:04,512] Trial 98 finished with value: 0.03508771929824561 and parameters: {'learning_rate': 0.07107491368165636, 'max_depth': 4, 'n_estimators': 434, 'min_child_weight': 2}. Best is trial 6 with value: 0.01754385964912286.\n",
      "[I 2025-07-10 18:49:04,788] Trial 99 finished with value: 0.01754385964912286 and parameters: {'learning_rate': 0.06010553143641521, 'max_depth': 5, 'n_estimators': 860, 'min_child_weight': 5}. Best is trial 6 with value: 0.01754385964912286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.05368479795193839, 'max_depth': 4, 'n_estimators': 584, 'min_child_weight': 4}\n",
      "Best score:  0.9824561403508771\n",
      "Test set accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 7)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    \n",
    "    # Create an XGBoost classifier\n",
    "    clf = XGBClassifier(\n",
    "        learning_rate=learning_rate, \n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators, \n",
    "        min_child_weight=min_child_weight\n",
    "    )\n",
    "    \n",
    "    # Train the classifier and calculate the accuracy on the validation set\n",
    "    clf.fit(x_train, y_train)\n",
    "    score = clf.score(x_test, y_test)\n",
    "    return 1.0 - score\n",
    "\n",
    "# Use Optuna to tune the hyperparameters\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best score\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best score: \", 1.0 - study.best_value)\n",
    "\n",
    "\n",
    "# Train the classifier with the best hyperparameters on the full training set\n",
    "best_params = study.best_params\n",
    "clf = XGBClassifier(\n",
    "    learning_rate=best_params[\"learning_rate\"], \n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    n_estimators=best_params[\"n_estimators\"], \n",
    "    min_child_weight=best_params[\"min_child_weight\"]\n",
    ")\n",
    "clf.fit(x, y)\n",
    "\n",
    "# Evaluate the tuned classifier on the test set\n",
    "score = clf.score(x_test, y_test)\n",
    "print(\"Test set accuracy: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a084e-8cd3-4bcb-bc3a-df53436a3eac",
   "metadata": {},
   "source": [
    "### Tuning Random Forest, Logistic Regression and Support Vector Classifier(SVC) with optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6fd81dd7-a966-4f57-91bd-685828a6312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "371cd427-79b8-48a3-97c5-0a7010745ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining models\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2090932c-6112-43ce-ab08-e320e7a8ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store model results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b50a0872-cf1f-4545-95fc-938ffb03deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid maximum iteration problem\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "414e4b17-aba6-4fbf-ae62-f650f5cb900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Logistic Regression\n",
    "for model in models:\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        param_grid = {\n",
    "            'C': [0.01, 0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'lbfgs'],\n",
    "            'max_iter': [100, 200, 500]\n",
    "        }\n",
    "        model = GridSearchCV(model, param_grid, cv=3, scoring='accuracy') # GridSearch CV\n",
    "# SVC\n",
    "    elif isinstance(model, SVC):\n",
    "        param_dist = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "        model = RandomizedSearchCV(model, param_dist, n_iter=5, cv=3, scoring='accuracy') # RandomizedSearch CV\n",
    "# Random Forest Classifier\n",
    "    elif isinstance(model, RandomForestClassifier):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5],\n",
    "        }\n",
    "        model = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[model.best_estimator_.__class__.__name__] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f89b4763-3709-4850-bfc4-9f6d382dc74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.9912280701754386\n",
      "precision: 0.9861111111111112\n",
      "recall: 1.0\n",
      "f1: 0.993006993006993\n",
      "SVC:\n",
      "accuracy: 0.9824561403508771\n",
      "precision: 0.9726027397260274\n",
      "recall: 1.0\n",
      "f1: 0.9861111111111112\n",
      "RandomForestClassifier:\n",
      "accuracy: 0.9649122807017544\n",
      "precision: 0.958904109589041\n",
      "recall: 0.9859154929577465\n",
      "f1: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d4ca8-72bd-4309-a610-06555588596c",
   "metadata": {},
   "source": [
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c682d71-9726-40a3-ab44-e30c585ffaf9",
   "metadata": {},
   "source": [
    "## 1. We have used three models: **Random Forest Classifier, Logistic Regression, SVC** on *breast cancer* dataset.\n",
    "## 2. **Logistic Regression**\n",
    "* **Accuracy:** 96.49%\n",
    "* **Precision:** 95.89%\n",
    "* **Recall:** 98.59%\n",
    "* **F1-score:** 97.22%\n",
    "* High precision and recall balance, making it a reliable and consistent model.\n",
    "## 3. **SVC (Support Vector Classifier)**\n",
    "* **Accuracy:** 94.74%\n",
    "* **Precision:** 92.21%\n",
    "* **Recall:** 100%\n",
    "* **F1-score:** 95.95%\n",
    "* Perfect recall indicates *zero false negatives*, which is excellent for use cases where missing a positive case is costly (e.g., medical diagnosis).\n",
    "* Slightly lower precision compared to others, suggesting more false positives.\n",
    "## 4. **Random Forest Classifier**\n",
    "* **Accuracy:** 96.49%\n",
    "* **Precision:** 95.89%\n",
    "* **Recall:** 98.59%\n",
    "* **F1-score:** 97.22%\n",
    "* Performs identically to Logistic Regression, showing high accuracy and a great balance of all metrics. Also benefits from model interpretability and feature importance.\n",
    "## 5. In terms of *accuracy* Logistic Regression and Random Forest Classifier have 96.49%.\n",
    "## 6. In terms of *recall* SVC is best as it has 100% recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0682de5-b6f5-4a4f-ab21-9801d83f6741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
